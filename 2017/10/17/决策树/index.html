<!DOCTYPE html><html lang="zh-cn"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="generator" content="Hi!Roy!"><title>决策树 - Hi!Roy!</title><meta name="author" content="Roy"><link rel="icon" href="http://www.hi-roy.com/assets/images/favicon.ico"><link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml"><meta name="description" content="决策树是机器学习中一种简单明了的分类算法，用程序语言描述就是if...elif...else...，关键问题则是如何选择合适的特征对数据集进行切割，常见算法有： ID3、C4.5、CART等。今天主要记录一下ID3这个算法，想使用这个算法首先要了解信息增益，想了解信息增益则要先明白什么是”熵”。熵描述了一个系统的混乱复杂程度，有一个理论叫做”熵增加”，含义就是一个没有外力干涉的系统混乱程度总是增加"><meta name="keywords" content="python"><meta property="og:type" content="blog"><meta property="og:title" content="决策树"><meta property="og:url" content="http://www.hi-roy.com/2017/10/17/决策树/index.html"><meta property="og:site_name" content="Hi!Roy!"><meta property="og:description" content="决策树是机器学习中一种简单明了的分类算法，用程序语言描述就是if...elif...else...，关键问题则是如何选择合适的特征对数据集进行切割，常见算法有： ID3、C4.5、CART等。今天主要记录一下ID3这个算法，想使用这个算法首先要了解信息增益，想了解信息增益则要先明白什么是”熵”。熵描述了一个系统的混乱复杂程度，有一个理论叫做”熵增加”，含义就是一个没有外力干涉的系统混乱程度总是增加"><meta property="og:locale" content="zh-cn"><meta property="og:updated_time" content="2019-09-16T08:11:51.517Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="决策树"><meta name="twitter:description" content="决策树是机器学习中一种简单明了的分类算法，用程序语言描述就是if...elif...else...，关键问题则是如何选择合适的特征对数据集进行切割，常见算法有： ID3、C4.5、CART等。今天主要记录一下ID3这个算法，想使用这个算法首先要了解信息增益，想了解信息增益则要先明白什么是”熵”。熵描述了一个系统的混乱复杂程度，有一个理论叫做”熵增加”，含义就是一个没有外力干涉的系统混乱程度总是增加"><meta property="og:image" content="http://www.hi-roy.com/assets/images/my.jpg"><link rel="stylesheet" href="/assets/css/style-sxklfps8ywgfyyjcowvnb4gxdgt0zjts3hsguljmv9uqanxjbnitrovtbrek.min.css"><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="//hm.baidu.com/hm.js?21513ec2bcd577b3297a1b16da82fa40";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script></head><body><div id="blog"><header id="header" data-behavior="4"><i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i><div class="header-title"><a class="header-title-link" href="/">Hi!Roy!</a></div><a class="header-right-icon" href="#about"><i class="fa fa-lg fa-question"></i></a></header><nav id="sidebar" data-behavior="4"><div class="sidebar-container"><div class="sidebar-profile"><a href="/#about"><img class="sidebar-profile-picture" src="/assets/images/my.jpg" alt="作者的图片"></a><h4 class="sidebar-profile-name">Roy</h4><h5 class="sidebar-profile-bio"><p>君以国士待我，我必以国士报君。</p></h5></div><ul class="sidebar-buttons"><li class="sidebar-button"><a class="sidebar-button-link" href="/"><i class="sidebar-button-icon fa fa-lg fa-home"></i> <span class="sidebar-button-desc">首页</span></a></li><li class="sidebar-button"><a class="sidebar-button-link" href="/all-categories"><i class="sidebar-button-icon fa fa-lg fa-bookmark"></i> <span class="sidebar-button-desc">分类</span></a></li><li class="sidebar-button"><a class="sidebar-button-link" href="/all-tags"><i class="sidebar-button-icon fa fa-lg fa-tags"></i> <span class="sidebar-button-desc">标签</span></a></li><li class="sidebar-button"><a class="sidebar-button-link" href="/all-archives"><i class="sidebar-button-icon fa fa-lg fa-archive"></i> <span class="sidebar-button-desc">归档</span></a></li><li class="sidebar-button"><a class="sidebar-button-link open-algolia-search" href="#search"><i class="sidebar-button-icon fa fa-lg fa-search"></i> <span class="sidebar-button-desc">搜索</span></a></li><li class="sidebar-button"><a class="sidebar-button-link" href="#about"><i class="sidebar-button-icon fa fa-lg fa-question"></i> <span class="sidebar-button-desc">关于</span></a></li></ul><ul class="sidebar-buttons"><li class="sidebar-button"><a class="sidebar-button-link" href="https://github.com/shenyushun" target="_blank" rel="noopener"><i class="sidebar-button-icon fa fa-lg fa-github"></i> <span class="sidebar-button-desc">GitHub</span></a></li><li class="sidebar-button"><a class="sidebar-button-link" href="mailto:darkcooking@gmail.com" target="_blank" rel="noopener"><i class="sidebar-button-icon fa fa-lg fa-envelope-o"></i> <span class="sidebar-button-desc">邮箱</span></a></li></ul><ul class="sidebar-buttons"><li class="sidebar-button"><a class="sidebar-button-link" href="/atom.xml"><i class="sidebar-button-icon fa fa-lg fa-rss"></i> <span class="sidebar-button-desc">RSS</span></a></li></ul></div></nav><div id="main" data-behavior="4" class="hasCoverMetaIn"><article class="post" itemscope itemtype="http://schema.org/BlogPosting"><div class="post-header main-content-wrap text-left"><h1 class="post-title" itemprop="headline">决策树</h1><div class="post-meta"><time itemprop="datePublished" datetime="2017-10-17T20:55:02+08:00">10月 17, 2017 </time><span>发布在 </span><a class="category-link" href="/source/all-categories/Python/">Python</a>, <a class="category-link" href="/source/all-categories/Python/机器学习/">机器学习</a></div></div><div class="post-content markdown" itemprop="articleBody"><div class="main-content-wrap"><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script><p>决策树是机器学习中一种简单明了的分类算法，用程序语言描述就是<code>if...elif...else...</code>，关键问题则是如何选择合适的特征对数据集进行切割，常见算法有： ID3、C4.5、CART等。</p><p>今天主要记录一下ID3这个算法，想使用这个算法首先要了解信息增益，想了解信息增益则要先明白什么是”熵”。熵描述了一个系统的混乱复杂程度，有一个理论叫做”熵增加”，含义就是一个没有外力干涉的系统混乱程度总是增加的，比如一个房间如果没人打扫的话只会越来越混乱，而不会自己变得整洁。</p><p>计算熵的公式如下：</p><p>$$H=-\sum_{i=i}^{n}P(x_i)log_2P(x_i)$$</p><p>其中\(P(x_i)\) 表示P发生的概率。</p><a id="more"></a><p>举个栗子，比如我们有下面这些数据：</p><table><thead><tr><th>饮料</th><th>肉类</th><th>水果</th><th>闹肚子</th></tr></thead><tbody><tr><td>牛奶</td><td>牛肉</td><td>香蕉</td><td>否</td></tr><tr><td>可乐</td><td>鸭肉</td><td>苹果</td><td>否</td></tr><tr><td>可乐</td><td>鸡肉</td><td>香蕉</td><td>是</td></tr><tr><td>牛奶</td><td>猪肉</td><td>苹果</td><td>否</td></tr><tr><td>咖啡</td><td>鱼肉</td><td>香蕉</td><td>是</td></tr></tbody></table><p>上面记录了食物和是否闹肚子之间的关系，那么闹肚子的概率<code>2/5</code>不闹肚子的概率是<code>3/5</code>，所以整个样本的熵就是：</p><p>$$-{2 \over 5}log_2{2 \over 5} - {3 \over 5}log_2{3 \over 5}\approx0.971$$</p><p>当水果吃香蕉的时候，闹肚子的概率为<code>2/3</code>不闹肚子的概率是<code>1/3</code>，所以当吃香蕉时候条件熵为： $$-{2 \over 3}log_2{2 \over 3} - {1 \over 3}log_2{1 \over 3}\approx0.918$$</p><p>同理，吃苹果时候从来不闹肚子，所以条件熵为0。</p><p>那么在特征”水果”上的信息增益就是：</p><p><code>0.971 - ((3/5)*0.918+(2/5)*0) = 0.42</code></p><p>注意计算信息增益时候需要将 <strong>条件熵乘以这个情形发生的概率</strong> 。</p><p>同理可以求得特征”饮料”的信息增益：0.571和特征”肉类”的信息增益：0.971。</p><p><strong>选择信息增益最大的特征来分割数据</strong>，所以选肉类。</p><p>计算熵的代码如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""构造数据集"""</span></span><br><span class="line">    <span class="keyword">return</span> [</span><br><span class="line">        [<span class="string">'milk'</span>,<span class="string">'beef'</span>,<span class="string">'banana'</span>,<span class="string">'N'</span>],</span><br><span class="line">        [<span class="string">'coca'</span>,<span class="string">'fish'</span>,<span class="string">'apple'</span>,<span class="string">'N'</span>],</span><br><span class="line">        [<span class="string">'coca'</span>,<span class="string">'beef'</span>,<span class="string">'banana'</span>,<span class="string">'Y'</span>],</span><br><span class="line">        [<span class="string">'milk'</span>,<span class="string">'pork'</span>,<span class="string">'apple'</span>,<span class="string">'N'</span>],</span><br><span class="line">        [<span class="string">'coffee'</span>,<span class="string">'fish'</span>,<span class="string">'banana'</span>,<span class="string">'Y'</span>],</span><br><span class="line">    ],[<span class="string">'drink'</span>,<span class="string">'meat'</span>,<span class="string">'fruit'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_dataset</span><span class="params">(dataset,col,val)</span>:</span></span><br><span class="line">    <span class="string">"""切分col列值为val的数据集"""</span></span><br><span class="line">    res_dataset = []</span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> dataset:</span><br><span class="line">        <span class="keyword">if</span> each[col] == val:</span><br><span class="line">            temp = each[:]</span><br><span class="line">            temp.remove(val)</span><br><span class="line">            res_dataset.append(temp)</span><br><span class="line">    <span class="keyword">return</span> res_dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_shannon_ent</span><span class="params">(dataset)</span>:</span></span><br><span class="line">    <span class="string">"""计算熵"""</span></span><br><span class="line">    count = len(dataset)</span><br><span class="line">    labels = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> dataset:</span><br><span class="line">        label = each[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> label <span class="keyword">not</span> <span class="keyword">in</span> labels.keys():</span><br><span class="line">            labels[label] = <span class="number">0</span></span><br><span class="line">        labels[label] += <span class="number">1</span></span><br><span class="line">    ent = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> one <span class="keyword">in</span> labels.keys():</span><br><span class="line">        prod = labels[one] / count</span><br><span class="line">        temp = prod * log(prod, <span class="number">2</span>)</span><br><span class="line">        ent += temp</span><br><span class="line">    <span class="keyword">return</span> -ent</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset,labels = create_dataset()</span><br><span class="line">print(calc_shannon_ent(dataset))</span><br><span class="line">sub_data = split_dataset(dataset,<span class="number">2</span>,<span class="string">'banana'</span>)</span><br><span class="line">print(sub_data)</span><br><span class="line">print(calc_shannon_ent(sub_data))</span><br></pre></td></tr></table></figure><p>输出如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">0.9709505944546686</span><br><span class="line">[[&apos;milk&apos;, &apos;beef&apos;, &apos;N&apos;], [&apos;coca&apos;, &apos;chicken&apos;, &apos;Y&apos;], [&apos;coffee&apos;, &apos;fish&apos;, &apos;Y&apos;]]</span><br><span class="line">0.9182958340544896</span><br></pre></td></tr></table></figure><p></p><p>接下来就是计算信息增益：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_feature2split</span><span class="params">(dataset)</span>:</span></span><br><span class="line">    <span class="string">"""返回信息增益最高的特征是第几列"""</span></span><br><span class="line">    best_infogain = <span class="number">0</span></span><br><span class="line">    best_feature_col = <span class="number">-1</span></span><br><span class="line">    all_count = len(dataset)</span><br><span class="line">    base_ent = calc_shannon_ent(dataset) <span class="comment"># 整个样本的熵</span></span><br><span class="line">    feature_num = len(dataset[<span class="number">0</span>]) - <span class="number">1</span> <span class="comment"># 这里有2个前提:数据集中列数相同，且最后一列为标签</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(feature_num):</span><br><span class="line">        feat_list = set([each[i] <span class="keyword">for</span> each <span class="keyword">in</span> dataset]) <span class="comment"># 得到某特征有多少不同的值</span></span><br><span class="line">        ent_temp = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> feat <span class="keyword">in</span> feat_list:</span><br><span class="line">            sub_dataset = split_dataset(dataset,i,feat)</span><br><span class="line">            prob = len(sub_dataset) / all_count <span class="comment"># 计算这种条件发生的概率</span></span><br><span class="line">            ent_temp += prob * calc_shannon_ent(sub_dataset)</span><br><span class="line">        tmp_infogain = base_ent - ent_temp</span><br><span class="line">        print(<span class="string">"col:%s,gain:%s"</span> % (i,tmp_infogain))</span><br><span class="line">        <span class="keyword">if</span> tmp_infogain &gt; best_infogain:</span><br><span class="line">            best_infogain = tmp_infogain</span><br><span class="line">            best_feature_col = i</span><br><span class="line">    <span class="keyword">return</span> best_feature_col</span><br></pre></td></tr></table></figure><p></p><p>输出如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">col:0,gain:0.5709505944546686</span><br><span class="line">col:1,gain:0.9709505944546686</span><br><span class="line">col:2,gain:0.4199730940219749</span><br></pre></td></tr></table></figure><p></p><p>ID3算法优点就是理解起来比较容易，缺点则是容易造成 <strong>过拟合</strong> 问题，另外在某些极端情况下，比如某个特征每一行值都独一无二(比如例子中的肉类)，这个算法倾向于优先根据此特征划分，效率极差。而且这个算法没法处理连续型数据，比较适合 <strong>类别较少的离散数据</strong>。</p><p>也因为如此，所以C4.5算法中使用 <strong><em>信息增益率</em></strong> 替换了信息增益判断，具体细节以后再写。接下来构造树：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tree</span><span class="params">(dataset,labels)</span>:</span></span><br><span class="line">    cls_list = [each[<span class="number">-1</span>] <span class="keyword">for</span> each <span class="keyword">in</span> dataset] <span class="comment"># 前提是最后一列为标签</span></span><br><span class="line">    <span class="keyword">if</span> len(set(cls_list)) == <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 当标签只剩一种时候返回</span></span><br><span class="line">        <span class="keyword">return</span> cls_list[<span class="number">0</span>]</span><br><span class="line">    best_feat_col = choose_feature2split(dataset)</span><br><span class="line">    best_feat_label = labels[best_feat_col]</span><br><span class="line">    tree = &#123;best_feat_label:&#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">for</span> val <span class="keyword">in</span> set([each[best_feat_col] <span class="keyword">for</span> each <span class="keyword">in</span> dataset]):</span><br><span class="line">        sub_labels = labels[:]</span><br><span class="line">        <span class="keyword">del</span>(sub_labels[best_feat_col])</span><br><span class="line">        tree[best_feat_label][val] = create_tree(split_dataset(dataset,best_feat_col,val),sub_labels)</span><br><span class="line">    <span class="keyword">return</span> tree</span><br></pre></td></tr></table></figure><p></p><p>输出如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dataset,labels = create_dataset()</span><br><span class="line">tree = create_tree(dataset,labels)</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">'meat'</span>: &#123;<span class="string">'beef'</span>: <span class="string">'N'</span>, <span class="string">'chicken'</span>: <span class="string">'Y'</span>, <span class="string">'duck'</span>: <span class="string">'N'</span>, <span class="string">'fish'</span>: <span class="string">'Y'</span>, <span class="string">'pork'</span>: <span class="string">'N'</span>&#125;&#125;</span><br></pre></td></tr></table></figure><p></p><p>可以看出，根据上面示例构造出的决策树仅仅根据<code>meat</code>来决定。</p><p>将原始数据集修改一下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [</span><br><span class="line">        [<span class="string">'milk'</span>, <span class="string">'beef'</span>, <span class="string">'banana'</span>, <span class="string">'N'</span>],</span><br><span class="line">        [<span class="string">'coca'</span>, <span class="string">'fish'</span>, <span class="string">'apple'</span>, <span class="string">'N'</span>],</span><br><span class="line">        [<span class="string">'coca'</span>, <span class="string">'beef'</span>, <span class="string">'banana'</span>, <span class="string">'Y'</span>],</span><br><span class="line">        [<span class="string">'milk'</span>, <span class="string">'pork'</span>, <span class="string">'apple'</span>, <span class="string">'Y'</span>],</span><br><span class="line">        [<span class="string">'coffee'</span>, <span class="string">'fish'</span>, <span class="string">'banana'</span>, <span class="string">'Y'</span>],</span><br><span class="line">    ],[<span class="string">'drink'</span>,<span class="string">'meat'</span>,<span class="string">'fruit'</span>]</span><br></pre></td></tr></table></figure><p></p><p>可以得到下面这中决策树：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">'drink'</span>: &#123;<span class="string">'coca'</span>: &#123;<span class="string">'meat'</span>: &#123;<span class="string">'beef'</span>: <span class="string">'Y'</span>, <span class="string">'fish'</span>: <span class="string">'N'</span>&#125;&#125;,</span><br><span class="line">           <span class="string">'coffee'</span>: <span class="string">'Y'</span>,</span><br><span class="line">           <span class="string">'milk'</span>: &#123;<span class="string">'meat'</span>: &#123;<span class="string">'beef'</span>: <span class="string">'N'</span>, <span class="string">'pork'</span>: <span class="string">'Y'</span>&#125;&#125;&#125;&#125;</span><br></pre></td></tr></table></figure><p></p><p>接下来进行分类：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(tree, labels, test_vec)</span>:</span></span><br><span class="line">    root_label = list(tree.keys())[<span class="number">0</span>]  <span class="comment"># py3中keys是一个生成器</span></span><br><span class="line">    sub_tree = tree[root_label]</span><br><span class="line">    feat_col = labels.index(root_label)  <span class="comment"># 找到特征是第几列</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> sub_tree.keys():</span><br><span class="line">        <span class="keyword">if</span> test_vec[feat_col] == key:</span><br><span class="line">            <span class="keyword">if</span> isinstance(sub_tree[key], dict):</span><br><span class="line">                cls_label = classify(sub_tree[key], labels, test_vec)  <span class="comment"># 判断节点</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                cls_label = sub_tree[key]  <span class="comment"># 叶子节点</span></span><br><span class="line">    <span class="keyword">return</span> cls_label</span><br><span class="line"></span><br><span class="line">print(classify(tree,labels,[<span class="string">'milk'</span>,<span class="string">'beef'</span>,<span class="string">'apple'</span>]))</span><br><span class="line">N</span><br></pre></td></tr></table></figure><p></p><p>输出了N，但如果我们把beef改成fish这种不在决策树中的情况，则会报错。这点也说明了这个算法的过拟合缺点。</p></div></div><div id="post-footer" class="post-footer main-content-wrap"><div class="post-footer-tags"><span class="text-color-light text-small">标签</span><br><a class="tag tag--primary tag--small t-link" href="/source/all-tags/python/">python</a></div><div class="post-actions-wrap"><nav><ul class="post-actions post-action-nav"><li class="post-action"><a class="post-action-btn btn btn--default tooltip--top" href="/2017/10/30/10分钟入门Pandas/" data-tooltip="10分钟入门Pandas"><i class="fa fa-angle-left"></i> <span class="hide-xs hide-sm text-small icon-ml">上一篇</span></a></li><li class="post-action"><a class="post-action-btn btn btn--default tooltip--top" href="/2017/10/14/Python验证码识别6/" data-tooltip="python验证码识别6:kNN"><span class="hide-xs hide-sm text-small icon-mr">下一篇</span> <i class="fa fa-angle-right"></i></a></li></ul></nav><ul class="post-actions post-action-share"><li class="post-action hide-lg hide-md hide-sm"><a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions"><i class="fa fa-share-alt"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-facebook-official"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-twitter"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-google-plus"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target="new" href="http://service.weibo.com/share/share.php?&amp;title=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-weibo"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target="new" href="http://connect.qq.com/widget/shareqq/index.html?url=http://www.hi-roy.com/2017/10/17/决策树/&amp;title=决策树"><i class="fa fa-qq"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target="new" href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-star"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target="new" href="http://widget.renren.com/dialog/share?resourceUrl=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-renren"></i></a></li><li class="post-action"><a class="post-action-btn btn btn--default" href="#"><i class="fa fa-list"></i></a></li></ul></div></div></article><footer id="footer" class="main-content-wrap"><span class="copyrights">Copyrights &copy; 2019 Roy. All Rights Reserved.</span></footer></div><div id="bottom-bar" class="post-bottom-bar" data-behavior="4"><div class="post-actions-wrap"><nav><ul class="post-actions post-action-nav"><li class="post-action"><a class="post-action-btn btn btn--default tooltip--top" href="/2017/10/30/10分钟入门Pandas/" data-tooltip="10分钟入门Pandas"><i class="fa fa-angle-left"></i> <span class="hide-xs hide-sm text-small icon-ml">上一篇</span></a></li><li class="post-action"><a class="post-action-btn btn btn--default tooltip--top" href="/2017/10/14/Python验证码识别6/" data-tooltip="python验证码识别6:kNN"><span class="hide-xs hide-sm text-small icon-mr">下一篇</span> <i class="fa fa-angle-right"></i></a></li></ul></nav><ul class="post-actions post-action-share"><li class="post-action hide-lg hide-md hide-sm"><a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions"><i class="fa fa-share-alt"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-facebook-official"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-twitter"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-google-plus"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target="new" href="http://service.weibo.com/share/share.php?&amp;title=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-weibo"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target="new" href="http://connect.qq.com/widget/shareqq/index.html?url=http://www.hi-roy.com/2017/10/17/决策树/&amp;title=决策树"><i class="fa fa-qq"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target="new" href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-star"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target="new" href="http://widget.renren.com/dialog/share?resourceUrl=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-renren"></i></a></li><li class="post-action"><a class="post-action-btn btn btn--default" href="#"><i class="fa fa-list"></i></a></li></ul></div></div><div id="share-options-bar" class="share-options-bar" data-behavior="4"><i id="btn-close-shareoptions" class="fa fa-close"></i><ul class="share-options"><li class="share-option"><a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-facebook-official"></i><span>分享到 Facebook</span></a></li><li class="share-option"><a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-twitter"></i><span>分享到 Twitter</span></a></li><li class="share-option"><a class="share-option-btn" target="new" href="https://plus.google.com/share?url=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-google-plus"></i><span>分享到 Google+</span></a></li><li class="share-option"><a class="share-option-btn" target="new" href="http://service.weibo.com/share/share.php?&amp;title=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-weibo"></i><span>分享到 Weibo</span></a></li><li class="share-option"><a class="share-option-btn" target="new" href="http://connect.qq.com/widget/shareqq/index.html?url=http://www.hi-roy.com/2017/10/17/决策树/&amp;title=决策树"><i class="fa fa-qq"></i><span>分享到 QQ</span></a></li><li class="share-option"><a class="share-option-btn" target="new" href="http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-star"></i><span>分享到 Qzone</span></a></li><li class="share-option"><a class="share-option-btn" target="new" href="http://widget.renren.com/dialog/share?resourceUrl=http://www.hi-roy.com/2017/10/17/决策树/"><i class="fa fa-renren"></i><span>分享到 Renren</span></a></li></ul></div></div><div id="about"><div id="about-card"><div id="about-btn-close"><i class="fa fa-remove"></i></div><img id="about-card-picture" src="/assets/images/my.jpg" alt="作者的图片"><h4 id="about-card-name">Roy</h4><div id="about-card-bio"><p>君以国士待我，我必以国士报君。</p></div><div id="about-card-job"><i class="fa fa-briefcase"></i><br><p>野生程序猿</p></div><div id="about-card-location"><i class="fa fa-map-marker"></i><br>China</div></div></div><div id="algolia-search-modal" class="modal-container"><div class="modal"><div class="modal-header"><span class="close-button"><i class="fa fa-close"></i></span> <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled"><span class="searchby-algolia-text text-color-light text-small">by</span> <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg"> </a><i class="search-icon fa fa-search"></i><form id="algolia-search-form"><input type="text" id="algolia-search-input" name="search" class="form-control input--large search-input" placeholder="Search "></form></div><div class="modal-body"><div class="no-result text-color-light text-center">没有找到文章</div><div class="results"><div class="media"><div class="media-body"><a class="link-unstyled" href="http://www.hi-roy.com/2013/02/12/Ubuntu下Gogant的简易破墙术/"><h3 class="media-heading">Ubuntu下Gogant的简易破墙术</h3></a><span class="media-meta"><span class="media-date text-small">2013年2月12日</span></span><div class="media-content hide-xs font-merryweather"></div></div><div style="clear:both"></div><hr></div><div class="media"><div class="media-body"><a class="link-unstyled" href="http://www.hi-roy.com/2013/10/31/python常用第三方库-转载/"><h3 class="media-heading">Python常用第三方库(转载)</h3></a><span class="media-meta"><span class="media-date text-small">2013年10月31日</span></span><div class="media-content hide-xs font-merryweather"></div></div><div style="clear:both"></div><hr></div><div class="media"><div class="media-body"><a class="link-unstyled" href="http://www.hi-roy.com/2013/11/01/fedora19安装ar8161网卡驱动/"><h3 class="media-heading">fedora19安装ar8161网卡驱动</h3></a><span class="media-meta"><span class="media-date text-small">2013年11月1日</span></span><div class="media-content hide-xs font-merryweather"></div></div><div style="clear:both"></div><hr></div><div class="media"><div class="media-body"><a class="link-unstyled" href="http://www.hi-roy.com/2013/11/01/fedora19源，rpmforge，fastestmirror/"><h3 class="media-heading">fedora19源，rpmforge，fastestmirror</h3></a><span class="media-meta"><span class="media-date text-small">2013年11月1日</span></span><div class="media-content hide-xs font-merryweather"></div></div><div style="clear:both"></div><hr></div><div class="media"><div class="media-body"><a class="link-unstyled" href="http://www.hi-roy.com/2013/11/01/python中如何自定义解析域名/"><h3 class="media-heading">python中如何自定义解析域名</h3></a><span class="media-meta"><span class="media-date text-small">2013年11月1日</span></span><div class="media-content hide-xs font-merryweather"></div></div><div style="clear:both"></div><hr></div><div class="media"><div class="media-body"><a class="link-unstyled" href="http://www.hi-roy.com/2013/11/01/django版本更换/"><h3 class="media-heading">django版本更换</h3></a><span class="media-meta"><span class="media-date text-small">2013年11月1日</span></span><div class="media-content hide-xs font-merryweather"></div></div><div style="clear:both"></div><hr></div><div class="media"><div class="media-body"><a class="link-unstyled" href="http://www.hi-roy.com/2013/11/01/django-groundwork个人1-5-3修改版/"><h3 class="media-heading">django-groundwork个人1.5.3修改版</h3></a><span class="media-meta"><span class="media-date text-small">2013年11月1日</span></span><div class="media-content hide-xs font-merryweather"></div></div><div style="clear:both"></div><hr></div><div class="media"><div class="media-body"><a class="link-unstyled" href="http://www.hi-roy.com/2013/11/01/fedora19美化/"><h3 class="media-heading">fedora19美化</h3></a><span class="media-meta"><span class="media-date text-small">2013年11月1日</span></span><div class="media-content hide-xs font-merryweather"></div></div><div style="clear:both"></div><hr></div><div class="media"><div class="media-body"><a class="link-unstyled" href="http://www.hi-roy.com/2013/11/01/装饰器/"><h3 class="media-heading">装饰器</h3></a><span class="media-meta"><span class="media-date text-small">2013年11月1日</span></span><div class="media-content hide-xs font-merryweather"></div></div><div style="clear:both"></div><hr></div><div class="media"><div class="media-body"><a class="link-unstyled" href="http://www.hi-roy.com/2013/11/01/SVN常用操作/"><h3 class="media-heading">SVN常用操作</h3></a><span class="media-meta"><span class="media-date text-small">2013年11月1日</span></span><div class="media-content hide-xs font-merryweather"></div></div><div style="clear:both"></div><hr></div></div></div><div class="modal-footer"><p class="results-count text-medium" data-message-zero="没有找到文章" data-message-one="找到 1 篇文章" data-message-other="找到 {n} 篇文章">找到 218 篇文章</p></div></div></div><div id="cover" style="background-image:url(/assets/images/cover.jpg)"></div><script src="/assets/js/script-ivwiy10zeb8fifc4swnhkwneuk64y53w2scmdmtp8thi9cqfxh31aowtroaz.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.14.1/moment-with-locales.min.js"></script><script src="//cdn.jsdelivr.net/algoliasearch/3/algoliasearch.min.js"></script><script>var algoliaClient=algoliasearch("51U8PIBLP6","16909d9ce1780cda71113841864e7aa8"),algoliaIndex=algoliaClient.initIndex("my-blog")</script></body></html>